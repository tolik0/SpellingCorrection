{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.fasttext import FastText\n",
    "from gensim.models.callbacks import CallbackAny2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data\\\\train.txt'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_FOLDER = \"data\\\\\"\n",
    "train_path = os.path.join(DATA_FOLDER, \"train.txt\")\n",
    "with open(train_path) as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [nltk.word_tokenize(re.sub(r\"[^a-z]+\", \" \", sentence.lower())) for sentence in nltk.sent_tokenize(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_text_model = FastText(size=300, workers=12)\n",
    "\n",
    "# build the vocabulary\n",
    "fast_text_model.build_vocab(data)\n",
    "\n",
    "# train the model\n",
    "fast_text_model.train(data, total_examples=model.corpus_count, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_text_model.save('models\\\\fasttext200k\\\\fasttext200k.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_output_word(model, context_words_list, topn=10):\n",
    "    \"\"\"Get the probability distribution of the center word given context words.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model: gensim.models.base_any2vec.BaseWordEmbeddingsModel\n",
    "            Model that predicts the output\n",
    "        context_words_list : list of str\n",
    "            List of context words.\n",
    "        topn : int, optional\n",
    "            Return `topn` words and their probabilities.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list of (str, float)\n",
    "            `topn` length list of tuples of (word, probability).\n",
    "\n",
    "    \"\"\"\n",
    "    if not model.negative:\n",
    "        raise RuntimeError(\n",
    "        \"We have currently only implemented predict_output_word for the negative sampling scheme, \"\n",
    "        \"so you need to have run word2vec with negative > 0 for this to work.\"\n",
    "        )\n",
    "\n",
    "    if not hasattr(model.wv, 'vectors') or not hasattr(model.trainables, 'syn1neg'):\n",
    "        raise RuntimeError(\"Parameters required for predicting the output words not found.\")\n",
    "\n",
    "    word_vocabs = [model.wv.vocab[w] for w in context_words_list if w in model.wv.vocab]\n",
    "    if not word_vocabs:\n",
    "        warnings.warn(\"All the input context words are out-of-vocabulary for the current model.\")\n",
    "        return None\n",
    "\n",
    "    word2_indices = [word.index for word in word_vocabs]\n",
    "\n",
    "    l1 = np.sum(model.wv.vectors[word2_indices], axis=0)\n",
    "    if word2_indices and model.cbow_mean:\n",
    "        l1 /= len(word2_indices)\n",
    "\n",
    "    # propagate hidden -> output and take softmax to get probabilities\n",
    "    prob_values = np.exp(np.dot(l1, model.trainables.syn1neg.T))\n",
    "    prob_values /= np.sum(prob_values)\n",
    "    top_indices = np.argsort(prob_values)[-topn:][::-1]\n",
    "    # returning the most probable output words with their probabilities\n",
    "    return [(model.wv.index2word[index1], prob_values[index1]) for index1 in top_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(size=300, workers=12)\n",
    "word2vec_model.build_vocab(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochLogger(CallbackAny2Vec):\n",
    "    '''Callback to log information about training'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(\"Epoch #{} start\".format(self.epoch))\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(\"Epoch #{} end\".format(self.epoch))\n",
    "        self.epoch += 1\n",
    "epoch_logger = EpochLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 start\n",
      "Epoch #0 end\n",
      "Epoch #1 start\n",
      "Epoch #1 end\n",
      "Epoch #2 start\n",
      "Epoch #2 end\n",
      "Epoch #3 start\n",
      "Epoch #3 end\n",
      "Epoch #4 start\n",
      "Epoch #4 end\n",
      "Epoch #5 start\n",
      "Epoch #5 end\n",
      "Epoch #6 start\n",
      "Epoch #6 end\n",
      "Epoch #7 start\n",
      "Epoch #7 end\n",
      "Epoch #8 start\n",
      "Epoch #8 end\n",
      "Epoch #9 start\n",
      "Epoch #9 end\n",
      "Epoch #10 start\n",
      "Epoch #10 end\n",
      "Epoch #11 start\n",
      "Epoch #11 end\n",
      "Epoch #12 start\n",
      "Epoch #12 end\n",
      "Epoch #13 start\n",
      "Epoch #13 end\n",
      "Epoch #14 start\n",
      "Epoch #14 end\n",
      "Epoch #15 start\n",
      "Epoch #15 end\n",
      "Epoch #16 start\n",
      "Epoch #16 end\n",
      "Epoch #17 start\n",
      "Epoch #17 end\n",
      "Epoch #18 start\n",
      "Epoch #18 end\n",
      "Epoch #19 start\n",
      "Epoch #19 end\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(744806832, 973533000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.train(data, total_examples=model.corpus_count, epochs=20, callbacks=[epoch_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model.save(\"models\\\\word2vec200k\\\\word2vec200k.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'level',\n",
       " 'of',\n",
       " 'postoperative',\n",
       " 'pain',\n",
       " 'and',\n",
       " 'nausea',\n",
       " 'was',\n",
       " 'scored',\n",
       " 'in',\n",
       " 'the',\n",
       " 'postanesthesia',\n",
       " 'care',\n",
       " 'unit',\n",
       " 'pacu',\n",
       " 'during',\n",
       " 'the',\n",
       " 'first',\n",
       " 'postoperative',\n",
       " 'hour',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'at',\n",
       " 'and',\n",
       " 'h',\n",
       " 'postoperatively']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent = \"The level of postoperative pain and nausea was scored in the postanesthesia care unit ( PACU ) during the first postoperative hour , as well as at 2 , 4 , 8 and 24h postoperatively .\"\n",
    "words = nltk.word_tokenize(re.sub(r\"[^a-z]+\", \" \", test_sent.lower()))\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_text_model = FastText.load(\"models\\\\fasttext200k\\\\fasttext200k.model\")\n",
    "word2vec_model = Word2Vec.load(\"models\\\\word2vec200k\\\\word2vec200k.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('relief', 0.005527567),\n",
       " ('intensity', 0.0034905642),\n",
       " ('shoulder', 0.0011541344),\n",
       " ('discomfort', 0.0009982137),\n",
       " ('analgesia', 0.00083989766),\n",
       " ('preoperative', 0.00077001157),\n",
       " ('severity', 0.0006258007),\n",
       " ('hypoesthesia', 0.00059391954),\n",
       " ('pain', 0.00056159665),\n",
       " ('back', 0.0005227166)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_output_word(word2vec_model, words[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('relief', 0.36741358),\n",
       " ('intensity', 0.0859091),\n",
       " ('alleviation', 0.0096091805),\n",
       " ('chest', 0.003944416),\n",
       " ('complained', 0.0035093569),\n",
       " ('neuropathic', 0.0034618857),\n",
       " ('back', 0.0027384593),\n",
       " ('severity', 0.0026988513),\n",
       " ('perception', 0.0019876296),\n",
       " ('shoulder', 0.001774376)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_output_word(fast_text_model, words[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.base_any2vec.BaseWordEmbeddingsModel"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fast_text_model).__base__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(words):\n",
    "    print(words)\n",
    "    return (predict_output_word(word2vec_model, words[:-1]), predict_output_word(fast_text_model, words[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'postanesthesia', 'care', 'unit', 'pacu']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('unit', 0.695053),\n",
       "  ('pacu', 0.057000123),\n",
       "  ('postanesthesia', 0.03609574),\n",
       "  ('care', 0.014875768),\n",
       "  ('arrival', 0.008621463),\n",
       "  ('stay', 0.0078104693),\n",
       "  ('intensive', 0.007062314),\n",
       "  ('postanaesthesia', 0.005120231),\n",
       "  ('ward', 0.0020113364),\n",
       "  ('postanesthetic', 0.0015265796)],\n",
       " [('intensive', 0.6312368),\n",
       "  ('postanesthesia', 0.15752365),\n",
       "  ('unit', 0.103116766),\n",
       "  ('usual', 0.06519048),\n",
       "  ('pacu', 0.00407928),\n",
       "  ('inpatient', 0.002983677),\n",
       "  ('orthogeriatric', 0.0024374798),\n",
       "  ('maternity', 0.0023734183),\n",
       "  ('cpu', 0.0020048202),\n",
       "  ('stay', 0.0018834673)])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check(words[10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
